# Artemis Complete Refactoring Roadmap

**Date:** 2025-10-24
**Status:** Comprehensive implementation guide for all three priorities
**Completion:** Estimated 8-12 hours total

---

## ğŸ“‹ Executive Summary

This document provides a complete roadmap for finishing all three major refactoring priorities:

1. **AI Query Service Integration** (5 remaining agents) - 4-6 hours
2. **UI/UX Stage Workflow Refactoring** (final touches) - 1-2 hours
3. **Split artemis_stages.py** (strict SRP compliance) - 3-4 hours

**Expected Benefits:**
- **38% average token reduction** across pipeline ($23,040/year savings at enterprise scale)
- **Zero code duplication** via DRY principle
- **Full SOLID compliance** with single-file-per-stage organization
- **Production-ready, maintainable codebase**

---

## ğŸ¯ Priority 1: AI Query Service Integration (5 Remaining Agents)

### **Overview**

Complete the KGâ†’RAGâ†’LLM centralization by refactoring the remaining 5 agents to use `AIQueryService`.

**Status:** 4/9 agents complete (44%)
**Remaining:** 5 agents
**Time:** 4-6 hours
**Token Savings:** 8,750 tokens/task (38% reduction)

---

### **Agent 1: Developer Agent** â­ HIGH IMPACT

**File:** `standalone_developer_agent.py`
**Current:** Lines 711-793 have duplicate KG query logic
**Token Savings:** ~3,000 tokens (38%)
**Time:** 90 minutes

#### Changes Required:

```python
# 1. Add imports (top of file, after existing imports)
from ai_query_service import (
    AIQueryService,
    create_ai_query_service,
    QueryType,
    AIQueryResult
)

# 2. Update __init__ (add ai_service parameter)
def __init__(
    self,
    developer_name: str,
    developer_type: str,
    llm_provider: str = "openai",
    llm_model: Optional[str] = None,
    logger: Optional[LoggerInterface] = None,
    rag_agent=None,
    ai_service: Optional[AIQueryService] = None  # NEW
):
    # ... existing init code ...

    # Initialize AI Query Service
    try:
        if ai_service:
            self.ai_service = ai_service
            if self.logger:
                self.logger.log("âœ… Using provided AI Query Service", "INFO")
        else:
            self.ai_service = create_ai_query_service(
                llm_client=self.llm_client,
                rag=rag_agent,
                logger=logger,
                verbose=False
            )
            if self.logger:
                self.logger.log("âœ… AI Query Service initialized", "INFO")
    except Exception as e:
        if self.logger:
            self.logger.log(f"âš ï¸  Could not initialize AI Query Service: {e}", "WARNING")
        self.ai_service = None

# 3. Remove _query_kg_for_implementation_patterns() method (lines 711-793)
# DELETE THIS ENTIRE METHOD - now handled by AIQueryService

# 4. Update execute() method to use AIQueryService
def execute(
    self,
    task_title: str,
    task_description: str,
    adr_content: str,
    adr_file: str,
    output_dir: Path,
    developer_prompt_file: str,
    card_id: str = "",
    rag_agent = None
) -> Dict:
    # ... existing code until line 133 ...

    # REPLACE lines 133-138 with:
    kg_context = None
    if self.ai_service:
        try:
            # Use AIQueryService instead of direct KG query
            result = self.ai_service.query(
                query_type=QueryType.CODE_GENERATION,
                prompt="",  # Will build full prompt later
                kg_query_params={
                    'task_title': task_title,
                    'task_description': task_description,
                    'keywords': task_title.lower().split()[:3]
                },
                skip_llm_call=True  # Only get KG context
            )

            if result.kg_context and result.kg_context.pattern_count > 0:
                kg_context = {
                    'similar_implementations_count': result.kg_context.pattern_count,
                    'code_patterns': result.kg_context.patterns_found[:3],
                    'estimated_token_savings': result.kg_context.estimated_token_savings
                }

                if self.logger:
                    self.logger.log(
                        f"ğŸ“Š Found {kg_context['similar_implementations_count']} similar implementations in KG",
                        "INFO"
                    )
                    self.logger.log(
                        f"   Using code patterns, saving ~{kg_context['estimated_token_savings']} tokens",
                        "INFO"
                    )
        except Exception as e:
            if self.logger:
                self.logger.log(f"âš ï¸  KG query failed: {e}", "WARNING")

    # ... rest of execute() remains the same ...

# 5. Add exception wrapping
from artemis_exceptions import (
    LLMClientError,
    LLMResponseParsingError,
    DeveloperExecutionError,
    RAGQueryError,
    FileReadError,
    wrap_exception,
    ArtemisException  # NEW
)
```

**Verification:**
```bash
cd /home/bbrelin/src/repos/salesforce/.agents/agile
python3 -m py_compile standalone_developer_agent.py
```

---

### **Agent 2: Project Analysis Agent** â­ MEDIUM IMPACT

**File:** `project_analysis_agent.py`
**Current:** Lines 289-506 have LLMPoweredAnalyzer with direct LLM calls
**Token Savings:** ~750 tokens (30%)
**Time:** 60 minutes

#### Changes Required:

```python
# 1. Add imports
from ai_query_service import (
    AIQueryService,
    create_ai_query_service,
    QueryType,
    AIQueryResult
)

# 2. Update ProjectAnalysisEngine.__init__
def __init__(
    self,
    analyzers: Optional[List[DimensionAnalyzer]] = None,
    llm_client: Optional[Any] = None,
    config: Optional[Any] = None,
    enable_llm_analysis: bool = True,
    ai_service: Optional[AIQueryService] = None,  # NEW
    rag: Optional[Any] = None  # NEW
):
    # ... existing code ...

    # Initialize AI Query Service if not provided
    if not ai_service and llm_client:
        try:
            ai_service = create_ai_query_service(
                llm_client=llm_client,
                rag=rag,
                logger=None,
                verbose=False
            )
        except Exception:
            ai_service = None

    self.ai_service = ai_service

    # Pass ai_service to LLMPoweredAnalyzer
    if enable_llm_analysis and llm_client:
        self.analyzers.append(LLMPoweredAnalyzer(llm_client, config, ai_service))

# 3. Update LLMPoweredAnalyzer
class LLMPoweredAnalyzer(DimensionAnalyzer):
    def __init__(
        self,
        llm_client: Optional[Any] = None,
        config: Optional[Any] = None,
        ai_service: Optional[AIQueryService] = None  # NEW
    ):
        self.llm_client = llm_client
        self.config = config
        self.ai_service = ai_service  # NEW

    def analyze(self, card: Dict, context: Dict) -> AnalysisResult:
        if not self.ai_service and not self.llm_client:
            return AnalysisResult(
                dimension="LLM-Powered Analysis",
                issues=[],
                recommendations=["LLM client not available"]
            )

        # Build prompt
        system_message = self._build_system_message()
        user_message = self._build_user_message(card, context)
        full_prompt = f"{system_message}\n\n{user_message}"

        try:
            # Use AIQueryService if available
            if self.ai_service:
                result = self.ai_service.query(
                    query_type=QueryType.PROJECT_ANALYSIS,
                    prompt=full_prompt,
                    kg_query_params={
                        'task_title': card.get('title', ''),
                        'keywords': card.get('title', '').lower().split()[:3]
                    },
                    temperature=0.3,
                    max_tokens=2000
                )

                if not result.success:
                    raise Exception(f"AI query failed: {result.error}")

                response = result.llm_response.content
            else:
                # Fallback to direct LLM call
                response = self.llm_client.generate_text(
                    system_message=system_message,
                    user_message=user_message,
                    temperature=0.3,
                    max_tokens=2000
                )

            # Parse and return
            analysis_data = self._parse_llm_response(response)
            issues = self._extract_issues(analysis_data)
            recommendations = analysis_data.get("recommendations", [])

            return AnalysisResult(
                dimension="LLM-Powered Comprehensive Analysis",
                issues=issues,
                recommendations=recommendations
            )
        except Exception as e:
            return AnalysisResult(
                dimension="LLM-Powered Analysis",
                issues=[],
                recommendations=[f"LLM analysis failed: {str(e)}"]
            )
```

---

### **Agent 3: UI/UX Stage** â­ LOW IMPACT (Already refactored for workflow)

**File:** `uiux_stage.py`
**Current:** No direct LLM calls, but could benefit from KG context for accessibility patterns
**Token Savings:** ~800 tokens (40%) - from pattern reuse
**Time:** 45 minutes

#### Changes Required:

```python
# 1. Add imports
from ai_query_service import (
    AIQueryService,
    create_ai_query_service,
    QueryType
)

# 2. Update __init__
def __init__(
    self,
    board: KanbanBoard,
    messenger: AgentMessenger,
    rag: RAGAgent,
    logger: LoggerInterface,
    observable: Optional[PipelineObservable] = None,
    supervisor: Optional['SupervisorAgent'] = None,
    config: Optional[Any] = None,
    ai_service: Optional[AIQueryService] = None  # NEW
):
    # ... existing init ...

    # Initialize AI Query Service
    try:
        if ai_service:
            self.ai_service = ai_service
        else:
            self.ai_service = create_ai_query_service(
                llm_client=None,  # UI/UX stage doesn't need LLM
                rag=rag,
                logger=logger,
                verbose=False
            )
            logger.log("âœ… AI Query Service initialized for pattern retrieval", "INFO")
    except Exception as e:
        logger.log(f"âš ï¸  Could not initialize AI Query Service: {e}", "WARNING")
        self.ai_service = None

# 3. Add method to query accessibility patterns before evaluation
def _query_accessibility_patterns(self, task_title: str) -> Optional[Dict]:
    """Query KG for similar UI/UX implementations and accessibility patterns"""
    if not self.ai_service:
        return None

    try:
        result = self.ai_service.query(
            query_type=QueryType.UIUX_EVALUATION,
            prompt="",  # Not calling LLM
            kg_query_params={
                'task_title': task_title,
                'file_types': ['html', 'css', 'javascript']
            },
            skip_llm_call=True  # Only get KG patterns
        )

        if result.kg_context and result.kg_context.pattern_count > 0:
            return {
                'patterns_found': result.kg_context.patterns_found,
                'pattern_count': result.kg_context.pattern_count
            }
    except Exception as e:
        self.logger.log(f"âš ï¸  Could not query accessibility patterns: {e}", "WARNING")

    return None

# 4. Use in _evaluate_developer_uiux (before evaluation)
def _evaluate_developer_uiux(...):
    # Query for accessibility patterns (best practices from KG)
    patterns = self._query_accessibility_patterns(task_title)
    if patterns:
        self.logger.log(
            f"ğŸ“š Found {patterns['pattern_count']} accessibility pattern(s) in KG",
            "INFO"
        )

    # ... rest of evaluation logic ...
```

---

### **Agent 4: Orchestrator Integration** â­ CRITICAL

**File:** `artemis_orchestrator.py`
**Current:** Initializes all stages individually
**Time:** 60 minutes

#### Changes Required:

```python
# 1. Add import at top
from ai_query_service import create_ai_query_service, AIQueryService

# 2. In main orchestration method, initialize AIQueryService ONCE
def run_pipeline(self, card_id: str) -> Dict:
    # ... existing code ...

    # Initialize AI Query Service (shared across all agents)
    self.logger.log("Initializing centralized AI Query Service...", "INFO")
    try:
        ai_service = create_ai_query_service(
            llm_client=llm_client,
            rag=rag_agent,
            logger=self.logger,
            verbose=self.verbose
        )
        self.logger.log("âœ… AI Query Service initialized successfully", "SUCCESS")
        self.logger.log("   All agents will use KG-First approach for token optimization", "INFO")
    except Exception as e:
        self.logger.log(f"âš ï¸  AI Query Service initialization failed: {e}", "WARNING")
        self.logger.log("   Agents will use direct LLM calls (no KG optimization)", "WARNING")
        ai_service = None

    # Pass ai_service to ALL stages
    architecture_stage = ArchitectureStage(
        board=board,
        messenger=messenger,
        rag=rag_agent,
        logger=self.logger,
        ai_service=ai_service  # NEW
    )

    development_stage = DevelopmentStage(
        board=board,
        messenger=messenger,
        rag=rag_agent,
        logger=self.logger,
        ai_service=ai_service  # NEW
    )

    code_review_stage = CodeReviewStage(
        board=board,
        messenger=messenger,
        rag=rag_agent,
        logger=self.logger,
        ai_service=ai_service  # NEW
    )

    project_analysis_stage = ProjectAnalysisStage(
        analyzers=None,
        llm_client=llm_client,
        config=config,
        enable_llm_analysis=True,
        ai_service=ai_service,  # NEW
        rag=rag_agent  # NEW
    )

    uiux_stage = UIUXStage(
        board=board,
        messenger=messenger,
        rag=rag_agent,
        logger=self.logger,
        ai_service=ai_service  # NEW
    )

    # ... rest of pipeline ...
```

---

## ğŸ¯ Priority 2: UI/UX Stage Final Touches

**File:** `uiux_stage.py`
**Status:** 95% complete (already refactored for workflow patterns)
**Remaining:** Just needs AIQueryService integration (covered in Priority 1)
**Time:** Already included in Agent 3 above

### âœ… Already Complete:

- âœ… Hydra configuration (no magic numbers)
- âœ… Value Objects (DeveloperEvaluation)
- âœ… Clock abstraction for testability (not needed for UI/UX stage)
- âœ… StageNotificationHelper (DRY observer pattern)
- âœ… Specific exceptions (UIUXEvaluationError, WCAGEvaluationError, GDPREvaluationError)
- âœ… List comprehensions throughout
- âœ… Agent communication via messenger
- âœ… Removed speculative generality (no NOT_EVALUATED fields)
- âœ… Knowledge Graph integration
- âœ… Supervisor integration

### ğŸ”„ Only Remaining: AIQueryService Integration

See **Agent 3** in Priority 1 above.

---

## ğŸ¯ Priority 3: Split artemis_stages.py (Strict SRP Compliance)

### **Overview**

Currently `artemis_stages.py` contains 7 stage classes in one file (~2,500 lines), violating Single Responsibility Principle. Split into separate files for true SOLID compliance.

**Time:** 3-4 hours
**Benefit:** Easier testing, maintenance, and independent evolution of stages

---

### **Current Structure:**

```
artemis_stages.py (2,500 lines)
â”œâ”€â”€ ProjectAnalysisStage
â”œâ”€â”€ RequirementsParsingStage
â”œâ”€â”€ ArchitectureStage
â”œâ”€â”€ DevelopmentStage
â”œâ”€â”€ ValidationStage
â”œâ”€â”€ IntegrationStage
â””â”€â”€ TestingStage
```

### **Target Structure:**

```
stages/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ project_analysis_stage.py        (300 lines)
â”œâ”€â”€ requirements_parsing_stage.py    (350 lines) [ALREADY DONE]
â”œâ”€â”€ architecture_stage.py            (400 lines)
â”œâ”€â”€ development_stage.py             (500 lines)
â”œâ”€â”€ validation_stage.py              (300 lines)
â”œâ”€â”€ integration_stage.py             (250 lines)
â””â”€â”€ testing_stage.py                 (300 lines)
```

---

### **Implementation Steps:**

#### **Step 1: Create stages/ directory** (5 minutes)

```bash
cd /home/bbrelin/src/repos/salesforce/.agents/agile
mkdir -p stages
touch stages/__init__.py
```

#### **Step 2: Extract each stage to separate file** (2-3 hours)

For each stage, follow this pattern:

```python
# stages/project_analysis_stage.py
#!/usr/bin/env python3
"""
Project Analysis Stage

Single Responsibility: Analyze project requirements before implementation
"""

from typing import Dict, Optional, Any
from artemis_stage_interface import PipelineStage, LoggerInterface
from kanban_manager import KanbanBoard
from agent_messenger import AgentMessenger
from rag_agent import RAGAgent
from project_analysis_agent import ProjectAnalysisEngine
from artemis_exceptions import ProjectAnalysisError, wrap_exception

# Import all dependencies this stage needs
# ... (copy imports from artemis_stages.py)

# Copy the ProjectAnalysisStage class definition from artemis_stages.py
class ProjectAnalysisStage(PipelineStage):
    # ... (exact same implementation as in artemis_stages.py)
    pass
```

**Files to create:**
1. `stages/project_analysis_stage.py` - Copy ProjectAnalysisStage class
2. `stages/architecture_stage.py` - Copy ArchitectureStage class
3. `stages/development_stage.py` - Copy DevelopmentStage class
4. `stages/validation_stage.py` - Copy ValidationStage class
5. `stages/integration_stage.py` - Copy IntegrationStage class
6. `stages/testing_stage.py` - Copy TestingStage class

#### **Step 3: Create stages/__init__.py** (10 minutes)

```python
#!/usr/bin/env python3
"""
Artemis Pipeline Stages

Each stage has Single Responsibility and is independently testable.
"""

from .project_analysis_stage import ProjectAnalysisStage
from .architecture_stage import ArchitectureStage
from .development_stage import DevelopmentStage
from .validation_stage import ValidationStage
from .integration_stage import IntegrationStage
from .testing_stage import TestingStage

__all__ = [
    'ProjectAnalysisStage',
    'ArchitectureStage',
    'DevelopmentStage',
    'ValidationStage',
    'IntegrationStage',
    'TestingStage'
]
```

#### **Step 4: Update imports in orchestrator** (15 minutes)

```python
# artemis_orchestrator.py

# BEFORE:
from artemis_stages import (
    ProjectAnalysisStage,
    ArchitectureStage,
    DevelopmentStage,
    ValidationStage,
    IntegrationStage,
    TestingStage
)

# AFTER:
from stages import (
    ProjectAnalysisStage,
    ArchitectureStage,
    DevelopmentStage,
    ValidationStage,
    IntegrationStage,
    TestingStage
)
```

#### **Step 5: Verify and test** (30 minutes)

```bash
# Syntax validation
python3 -m py_compile stages/project_analysis_stage.py
python3 -m py_compile stages/architecture_stage.py
python3 -m py_compile stages/development_stage.py
python3 -m py_compile stages/validation_stage.py
python3 -m py_compile stages/integration_stage.py
python3 -m py_compile stages/testing_stage.py
python3 -m py_compile stages/__init__.py

# Import test
python3 -c "from stages import ProjectAnalysisStage, ArchitectureStage; print('âœ… Imports work')"

# Run orchestrator with new imports
python3 artemis_orchestrator.py --help
```

#### **Step 6: Archive old file** (5 minutes)

```bash
# Backup original
mv artemis_stages.py artemis_stages_original_backup.py

# Create compatibility shim (optional, for backward compatibility)
cat > artemis_stages.py << 'EOF'
#!/usr/bin/env python3
"""
Backward compatibility shim for artemis_stages.py

All stages have been moved to stages/ directory.
This file maintains import compatibility.
"""

from stages import (
    ProjectAnalysisStage,
    ArchitectureStage,
    DevelopmentStage,
    ValidationStage,
    IntegrationStage,
    TestingStage
)

__all__ = [
    'ProjectAnalysisStage',
    'ArchitectureStage',
    'DependencyValidationStage',
    'DevelopmentStage',
    'ValidationStage',
    'IntegrationStage',
    'TestingStage'
]

# Deprecated warning
import warnings
warnings.warn(
    "artemis_stages.py is deprecated. Import from 'stages' package instead.",
    DeprecationWarning,
    stacklevel=2
)
EOF
```

---

## ğŸ“Š Completion Checklist

### Priority 1: AI Query Service (5 agents)

- [ ] Developer Agent refactored
  - [ ] Add AIQueryService imports
  - [ ] Update __init__ with ai_service parameter
  - [ ] Replace _query_kg_for_implementation_patterns with AIQueryService
  - [ ] Test and verify syntax
  - [ ] Measure token savings (~3,000 tokens)

- [ ] Project Analysis Agent refactored
  - [ ] Add AIQueryService imports
  - [ ] Update ProjectAnalysisEngine.__init__
  - [ ] Update LLMPoweredAnalyzer to use AIQueryService
  - [ ] Test and verify syntax
  - [ ] Measure token savings (~750 tokens)

- [ ] UI/UX Stage refactored
  - [ ] Add AIQueryService imports
  - [ ] Update __init__ with ai_service parameter
  - [ ] Add _query_accessibility_patterns method
  - [ ] Test and verify syntax
  - [ ] Measure token savings (~800 tokens)

- [ ] Orchestrator updated
  - [ ] Add AIQueryService import
  - [ ] Initialize AIQueryService once at orchestrator level
  - [ ] Pass ai_service to all stages
  - [ ] Test end-to-end pipeline
  - [ ] Verify all stages use shared service

- [ ] Supervisor Agent refactored (bonus - not critical path)
  - [ ] Add AIQueryService for error recovery
  - [ ] Update error recovery methods
  - [ ] Test recovery workflows

### Priority 2: UI/UX Stage Final Touches

- [x] Configuration management (DONE)
- [x] Value Objects (DONE)
- [x] Observer pattern helper (DONE)
- [x] Specific exceptions (DONE)
- [x] List comprehensions (DONE)
- [x] Remove speculative generality (DONE)
- [ ] AIQueryService integration (covered in Priority 1)

### Priority 3: Split artemis_stages.py

- [ ] Create stages/ directory
- [ ] Extract ProjectAnalysisStage to stages/project_analysis_stage.py
- [ ] Extract ArchitectureStage to stages/architecture_stage.py
- [ ] Extract DevelopmentStage to stages/development_stage.py
- [ ] Extract ValidationStage to stages/validation_stage.py
- [ ] Extract IntegrationStage to stages/integration_stage.py
- [ ] Extract TestingStage to stages/testing_stage.py
- [ ] Create stages/__init__.py
- [ ] Update orchestrator imports
- [ ] Verify all syntax
- [ ] Run integration tests
- [ ] Archive original file

---

## ğŸ¯ Expected Final Results

### Token Savings (Full Pipeline)

| Component | Before | After | Savings | % Reduction |
|-----------|--------|-------|---------|-------------|
| Requirements Parser | 2,300 | 1,500 | 800 | 35% |
| Architecture Stage | 1,200 | 800 | 400 | 33% |
| Code Review | 5,000 | 3,000 | 2,000 | 40% |
| Developer Agent | 8,000 | 5,000 | 3,000 | 38% |
| Project Analysis | 2,500 | 1,750 | 750 | 30% |
| Supervisor | 1,500 | 500 | 1,000 | 67% |
| UI/UX Stage | 2,000 | 1,200 | 800 | 40% |
| **Total** | **22,500** | **13,750** | **8,750** | **38% avg** |

### Cost Savings

**At 10,000 tasks/month:**
- Before: $5,050/month
- After: $3,130/month
- **Savings: $1,920/month**
- **Annual: $23,040/year**

### Code Quality Improvements

- **Zero Code Duplication** - DRY principle across all agents
- **Full SOLID Compliance** - All stages in separate files
- **Exception Safety** - All exceptions properly wrapped
- **Maintainability** - Single file per stage = easier testing
- **Testability** - Mock AIQueryService for unit tests
- **Extensibility** - Easy to add new query types

---

## ğŸš€ Quick Start Commands

### Run Full Refactoring (Automated Script)

```bash
cd /home/bbrelin/src/repos/salesforce/.agents/agile

# Step 1: Refactor Developer Agent
# (Apply changes from Priority 1, Agent 1 above)
# Test: python3 -m py_compile standalone_developer_agent.py

# Step 2: Refactor Project Analysis Agent
# (Apply changes from Priority 1, Agent 2 above)
# Test: python3 -m py_compile project_analysis_agent.py

# Step 3: Refactor UI/UX Stage
# (Apply changes from Priority 1, Agent 3 above)
# Test: python3 -m py_compile uiux_stage.py

# Step 4: Update Orchestrator
# (Apply changes from Priority 1, Agent 4 above)
# Test: python3 artemis_orchestrator.py --help

# Step 5: Split artemis_stages.py
mkdir -p stages
# (Follow steps from Priority 3 above)
# Test: python3 -c "from stages import ProjectAnalysisStage; print('âœ…')"

# Step 6: Integration test
python3 artemis_orchestrator.py --card-id test-001 --full
```

---

## ğŸ“ Documentation Updates Needed

After completing all refactoring:

1. Update `AI_QUERY_SERVICE_GUIDE.md` - Mark all 9 agents as complete
2. Update `REFACTORING_STATUS.md` - Update completion percentage to 100%
3. Create `REFACTORING_COMPLETE_ALL_PRIORITIES.md` - Final summary
4. Update `README.md` - Document new stages/ directory structure
5. Update any diagrams/architecture docs with new structure

---

## âš ï¸ Important Notes

1. **Test After Each Agent** - Don't batch refactoring, test incrementally
2. **Backup Before Splitting** - Create `artemis_stages_original_backup.py`
3. **Verify Imports** - Ensure all imports work after splitting stages
4. **Run Integration Tests** - Test full pipeline after orchestrator update
5. **Monitor Token Usage** - Verify actual savings match estimates
6. **Update Documentation** - Keep docs in sync with code changes

---

## ğŸ‰ Success Criteria

All refactoring is complete when:

- âœ… All 9 agents use AIQueryService (no duplicate KG query code)
- âœ… UI/UX Stage has all workflow patterns applied
- âœ… All stages in separate files under stages/ directory
- âœ… All syntax validation passes
- âœ… Integration tests pass
- âœ… Token savings verified (38% reduction measured)
- âœ… Documentation updated
- âœ… No regressions in functionality

---

**Date:** 2025-10-24
**Author:** Claude Code
**Status:** Ready for implementation
**Estimated Completion:** 8-12 hours total work
